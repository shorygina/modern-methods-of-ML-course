{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2.\n",
    "\n",
    "Продолжаем знакомиться с библиотекой `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 -- tensorflow vs numpy (3 балла).\n",
    "\n",
    "Сравните скорость работы функций над массивами в фреймворках tensorflow и numpy. Для этого реализуйте на нампае и тф'е следующее:\n",
    "\n",
    " * Сумму квадратов диагональных элементов квадратной матрицы. Например для матрицы\n",
    "$$\n",
    " \\begin{pmatrix}\n",
    "     1& 0& 5\\\\\n",
    "     -2& 8& 12\\\\\n",
    "     4& 1& -5\n",
    " \\end{pmatrix}\n",
    "$$\n",
    " такая сумма будет равна $1^2 + 8^2 + (-5)^2 = 90$.\n",
    " * Угол между векторами в n-мерном пространстве. Напомним, что он вычисляется по формуле\n",
    " $$\n",
    "     \\arccos \\cfrac{\\left\\langle x, y\\right\\rangle}{||x||\\cdot ||y||}\n",
    " $$\n",
    "\n",
    " * Сумму элементов коммутатора квадратных матриц $A$ и $B$. Коммутатор матриц это матрица $C = AB - BA$.\n",
    " \n",
    "Постройте графики зависимости времени выполнения операций от размера массивов (в логарифмическй шкале) для каждой задачи для tensorflow и numpy (три рисунка, по два графика на рисунок). Элементы матриц выбирайте случайным образом (через модуль tf.random и np.random соотвтетственно). Какой фреймворк оказывается быстрее? Как Вы думаете, почему?\n",
    "\n",
    "Можете пользоваться образцом кода ниже.\n",
    "\n",
    "**Замечание**. Графики должны быть опрятными! Подписывайте оси и единицы измерения, указывайте легенду. За неопрятные графики оценка за задание может быть снижена.\n",
    "\n",
    "**Подсказка**. Функция time.time() возвращает время в секундах (с высокой точностью), прошедшее от 00:00 1 января 1970 года. Используйте её, чтобы посчитать, сколько длилось выполнение куска кода. Также вам могут пригодиться функции `tf.linalg.norm`, `tf.diag_part`, `tf.acos`, `tf.matmul`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "for n in [<define array size>]:\n",
    "    x = # define array(-s) of size n\n",
    "    ...\n",
    "    y = # define operaton\n",
    "    ...\n",
    "    begin = time.time()\n",
    "    sess.run(y)\n",
    "    end = time.time()\n",
    "    time_spent = end - begin\n",
    "    # remember time_spent\n",
    "    ...\n",
    "\n",
    "# The same but for numpy\n",
    "...\n",
    "\n",
    "\n",
    "# plot results\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 -- градиенты и оптимайзеры (3 балла).\n",
    "\n",
    "Продолжим работать с датасетом MNIST с размером картинок 8х8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "mnist = load_digits()\n",
    "\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "n_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие алгоритмы оптимизации имплементированы в `tensorflow`. В этом задании мы сравним их при одинаковых параметрах, а также переберём разные параметры для одного алгоритма.\n",
    "\n",
    "**Задание 2.1** (1.5 балла). Исследуйте вклад параметра momentum в методу `tf.train.MomentumOptimizer`. Для этого для разных значений momentum постройте графики значения функции потерь от номера итерации. При каких значениях momentum алгоритм сходится быстрее? Используйте `learning_rate=0.01`.\n",
    "\n",
    "**Замечание**. В этом задании используется многоклассовая логистическая регрессия. Не меняйте код модели в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "w = tf.Variable(np.ones((X.shape[1], n_labels)), dtype=\"float32\")\n",
    "X_input = tf.placeholder(\"float32\", (None, X.shape[1]))\n",
    "y_input = tf.placeholder(\"int32\", (None,))\n",
    "\n",
    "predicted = tf.nn.softmax(X_input @ w)\n",
    "loss = tf.losses.log_loss(tf.one_hot(y_input, depth=n_labels), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, train_op, batch_size=16):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        n_batch_train = len(X) // batch_size\n",
    "        for epoch in range(1):\n",
    "            loss_history = []\n",
    "            for b in range(n_batch_train):\n",
    "                _, loss_ = sess.run([train_op, loss], feed_dict={X_input: X[b*batch_size:(b+1)*batch_size],\n",
    "                                                                 y_input: y[b*batch_size:(b+1)*batch_size]\n",
    "                                                                 })\n",
    "                loss_history.append(loss_)\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.2** (0.5 баллa). Исследуйте вклад `learning_rate`. Для этого для разных значений `learning_rate` постройте графики значения функции потерь от номера итерации. При каких значениях длины шага градиентного спуска алгоритм сходится быстрее? Используйте параметр метод MomentumOptimizer с параметром, который вы считаете лучшим по итогам предыдущего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.3** (0.5 балла) Проделайте то же, что и в пункте выше, но используйте в качестве базового алгоритма оптимизации `Adam` с дефолтными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.4** (0.5 балла) Сравните алгоритмы `Adam` и `Momentum` для данной задачи. Какой показывает себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 -- наша первая нейросеть, часть 2 (4 балла).\n",
    "\n",
    "В этом задании мы напишем нейросеть для работы с датасетом MNIST размера 28х28. Исользовать можно только полносвязные (dense) слои! Для этого мы \"вытянем\" картинки 28х28 в длинный вектор размера 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_dataset\n",
    "\n",
    "X_train, y_train, X_test, y_test, _, _ = load_dataset()\n",
    "\n",
    "X_train = X_train.reshape(len(X_train), -1)\n",
    "X_test = X_test.reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [228, 1437, 322, 420, 69]:\n",
    "    plt.title(y_train[i])\n",
    "    plt.imshow(X_train[i].reshape((28, 28)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите архитектуру и алгоритм оптимизации так, чтобы значение accuracy на тестовой выборке было не менее 97.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def train_and_validate(X_train, y_train, X_test, y_test, train_op, batch_size=16):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        n_batch_train = len(X_train) // batch_size\n",
    "        n_batch_test = len(X_test) // batch_size\n",
    "        for epoch in range(1):\n",
    "            loss_history_train = []\n",
    "            for b in range(n_batch_train):\n",
    "                _, loss_ = sess.run([train_op, loss], feed_dict={X_input: X_train[b*batch_size:(b+1)*batch_size],\n",
    "                                                                 y_input: y_train[b*batch_size:(b+1)*batch_size]\n",
    "                                                                 })\n",
    "                loss_history_train.append(loss_)\n",
    "\n",
    "        for epoch in range(1):\n",
    "            loss_history_test = []\n",
    "            prediction_history = []\n",
    "            for b in range(n_batch_test):\n",
    "                loss_, predicted_ = sess.run([loss, predicted], feed_dict={X_input: X_test[b*batch_size:(b+1)*batch_size],\n",
    "                                                                 y_input: y_test[b*batch_size:(b+1)*batch_size]\n",
    "                                                                 })\n",
    "                loss_history_test.append(loss_)\n",
    "                prediction_history += predicted_.argmax(-1).tolist()\n",
    "            print(\"Test accuracy: \", accuracy_score(y_test, prediction_history))\n",
    "    return loss_history_train, loss_history_test\n",
    "\n",
    "X_input = tf.placeholder(\"float32\", (None, 784)) # dim = [batch_size, 784]\n",
    "y_input = tf.placeholder(\"int32\", (None,)) # dim = [batch_size,]\n",
    "\n",
    "layer1 = #<define architecture as a function of X_input>\n",
    "...\n",
    "predicted = #<define 10-class outputs>\n",
    "\n",
    "loss = #<define log loss with one-hot vector of labels\n",
    "train_op = #<define train operation here>\n",
    "\n",
    "loss_history_train, loss_history_test = train_and_validate(X_train, y_train, X_test, y_test, train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4 (0.1 баллов).\n",
    "\n",
    "**Задание 4.1**. (0.1 баллов) Оставьте ниже смешную картинку (желательно про машинное обучение). Лучшую картинку мы поставим на аватарку чатика \"Флуд про ИАД\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.2**. Напищите ниже фидбек по заданию и по курсу в целом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
